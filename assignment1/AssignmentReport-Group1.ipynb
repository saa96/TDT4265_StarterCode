{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "$$C^n(\\omega) = -(y^n \\cdot ln(\\hat y ^n) + (1-y^n)\\cdot ln(1 - \\hat y ^n))$$\n",
    "$$\\hat y = f(x) = \\frac{1}{1+exp(-z)}, \\rightarrow  z = \\omega^T\\cdot x = \\sum _i^I \\omega_i \\cdot x_i$$\n",
    "Assuming the $y^n$ vector is constant:\n",
    "$$\\frac{\\partial C^n}{\\partial \\omega _i} = -\\frac{\\partial}{\\partial \\omega _i} \\left(y^n \\cdot ln(f(x^n))\\right) - \\frac{\\partial}{\\partial \\omega _i} \\left((1-y^n)\\cdot ln(1 - f(x^n))\\right)$$\n",
    "\n",
    "Performing the partial derivation on the two seperate terms in the previous equation we get:\n",
    "\n",
    "Starting with the first term: \n",
    "$$First = -y^n \\cdot \\frac{\\partial}{\\partial \\omega _i} (ln(f(x^n))) = -y^n \\cdot \\frac{1}{f(x^n)}\\cdot \\frac{\\partial f(x^n)}{\\partial \\omega _i} = -\\frac{y^n}{f(x^n)} \\cdot \\frac{x_i^n \\cdot exp(-z)}{(1+exp(-z))^2} = -y^n \\hat y^n x_i^n \\cdot exp(-z)$$\n",
    "\n",
    "Continuing with the second term:\n",
    "$$Second = -(1-y^n)\\frac{1}{1-f(x^n)} \\cdot \\left(-\\frac{x_i^n \\cdot exp(-z)}{(1+exp(-z))^2} \\right)$$\n",
    "\n",
    "Expanding on what $1-f(x^n)$ is:\n",
    "$$ 1-f(x^n) = \\frac{1+exp(-z)}{1+exp(-z)} - \\frac{1}{1+exp(-z)} = \\frac{exp(-z)}{1+exp(-z)}$$\n",
    "Hence;\n",
    "$$\\frac{1}{1-f(x^n)} = \\frac{1+exp(-z)}{exp(-z)} = \\frac{1}{exp(-z)} \\cdot \\frac{1}{f(x^n)}$$\n",
    "\n",
    "Going back to the $second$ term:\n",
    "$$ -(1-y^n) \\frac{1}{exp(-z)} \\cdot \\frac{1}{f(x^n)} \\cdot \\left(-\\frac{x_i^n \\cdot exp(-z)}{(1+exp(-z))^2} \\right) = -(1-y^n) \\frac{1}{exp(-z)} \\cdot \\frac{1}{f(x^n)} \\cdot (-x_i^n \\cdot exp(-z) \\cdot f(x^n)^2)$$\n",
    "Hence;\n",
    "$$Second = (1-y^n)\\cdot x_i^n \\hat y^n$$\n",
    "\n",
    "This gives us:\n",
    "$$\\frac{\\partial C^n}{\\partial \\omega _i} = x_i^n \\left( -y^n \\hat y^n \\cdot exp(-z) + (1-y^n)\\cdot \\hat y^n\\right) = x_i^n \\left( -y^n \\hat y^n \\cdot exp(-z) + \\hat y^n -y^n \\hat y^n \\right) = x_i^n ( \\hat y^n - y^n \\hat y^n(1-exp(-z)))$$\n",
    "\n",
    "Seeing that $(1-exp(-z))$ = \\frac{1}{f(x^n)}, we finaly get:\n",
    "\n",
    "$$\\frac{\\partial C^n}{\\partial \\omega _i} = x_i^n(\\hat y^n - y^n) = -( y^n - \\hat y^n)x_i^n \\rightarrow QED$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "To find the derivative of $\\frac{\\partial C^n}{\\partial \\omega _{k,j}}$ we split the derivation into two main parts. The first one beign to find the derivative of $\\hat y_k^n$ $\\rightarrow \\frac{\\partial \\hat y_k^n}{\\partial \\omega_{k,j}}$, then find the derivitive of $C_k^n$ $\\rightarrow \\frac{\\partial C_k^n}{\\partial \\omega_{k,j}}$\n",
    "\n",
    "Starting with $\\frac{\\partial \\hat y_k^n}{\\partial \\omega_{k,j}}$ we have that:\n",
    "$$\\hat y_k^n = \\frac{exp(z_k^n)}{\\sum _{k'}^K exp(z_k^n)}, \\rightarrow z_k^n = \\omega^T x^n$$\n",
    "\n",
    "For the derivation of this expression we have two cases, the first where $i=j$, the second where $i \\neq j$. Starting at the first we get the following:\n",
    "\n",
    "$$ \\frac{\\partial \\hat y_k^n}{\\partial \\omega_{k,j}} = \\frac{x_j^n \\cdot \\sum _{k'}^K exp(z_k^n) - exp(z_k^n) x_i^n exp(z_k^n)}{(\\sum _{k'}^K exp(z_k^n))^2} = x_j^n \\left(\\frac{exp(z_k^n)}{\\sum exp(z_k^n)} \\cdot \\left(\\frac{\\sum exp(z_k^n)- exp(z_k^n)}{\\sum exp(z_k^n)}\\right)\\right)$$ \n",
    "\n",
    "Using that: $$\\frac{\\sum exp(z_k^n)- exp(z_k^n)}{\\sum exp(z_k^n)} = \\frac{\\sum exp(z_k^n)}{\\sum exp(z_k^n)} - \\frac{exp(z_k^n)}{\\sum exp(z_k^n)} = 1 - \\hat y_k^n$$\n",
    "\n",
    "We get that: $$\\frac{\\partial \\hat y_k^n}{\\partial \\omega_{k,j}} = x_j^n(\\hat y_{k,j}^n(1 - \\hat y_{k,j}^n))$$\n",
    "\n",
    "For the second case, $i \\neq j$, we have that:\n",
    "$$\\frac{\\partial \\hat y_k^n}{\\partial \\omega_{k,i}} = \\frac{0 - exp(z_{k,j}^n) x_i^n exp(z_{k,j}^n)}{\\sum _{k'}^K exp(z_k^n)^2} = -x_i^n \\hat y_{k,j}^n \\hat y_{k,i}^n = -x_j^n \\hat y_{k,j}^n \\hat y_{k,i}^n \\xrightarrow ? \\text{got a bit confused with the indeces here?} $$\n",
    "\n",
    "Having these expressions we can start at $\\frac{\\partial C_k^n}{\\partial \\omega_{k,j}}$. Knowing that $C_{k,j}^n$ $= -\\sum_j^J$ $y_{k,j}^n$ $ln(\\hat y_{k,j}^n)$ we get that: \n",
    "\n",
    "$$\\frac{\\partial C_k^n}{\\partial \\hat y_{k,j}^n} = - \\sum _j^J y_{k,j}^n \\frac{1}{\\hat y_{k,j}^n}$$\n",
    "\n",
    "Next this have to be differentiated with respect to $\\omega_{k,j}$ (can we just drop the indeces from the output and target vectors? assuming we can do so we get):\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial C_k^n}{\\partial \\omega_{k,j}} = - \\sum _{j\\neq i} y_{k,j}^n \\frac{1}{\\hat y_{k,j}^n} \\frac{\\partial \\hat y_{k,j}^n}{\\partial \\omega _{k,i}} - y_{k,j}^n \\frac{1}{\\hat y_{k,j}^n} \\frac{\\partial \\hat y_{k,j}^n}{\\partial \\omega _{k,j}} = - \\sum _{j\\neq i} y_{k,j}^n \\frac{1}{\\hat y_{k,j}^n} (-x_j^n \\hat y_{k,j}^n \\hat y_{k,i}^n) - y_{k,j}^n \\frac{1}{\\hat y_{k,j}^n} (x_j^n(\\hat y_{k,j}^n(1 - \\hat y_{k,j}^n)))$$\n",
    "$$ = \\sum _{j\\neq i} y_{k,j}^n x_i^n \\hat y_{k,i}^n - y_{k,j}^n x_j^n + \\hat y_{k,j}^ny_{k,j}^n x_j^n$$\n",
    "\n",
    "Due to the vectors being one-hot encoded we get that:\n",
    "\n",
    "$$\\frac{\\partial C_k^n}{\\partial \\omega_{k,j}} = x_i^n \\hat y_{k,i}^n - y_{k,j}^n x_j^n + \\hat y_{k,j}^ny_{k,j}^n x_j^n$$\n",
    "\n",
    "Assuming that $j=i$ for the resulting expression, giving that:\n",
    "\n",
    "$$\\frac{\\partial C_k^n}{\\partial \\omega_{k,j}} = x_j^n(\\hat y_{k,j}^n - y_{k,j}^n(1 - \\hat y_{k,j}^n)) = -x_j^n (y_k^n(1 - \\hat y_{k,j}^n) - \\hat y_{k,j}^n) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "![](task2b_binary_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](task2b_binary_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "FILL IN ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2e)\n",
    "FILL IN ANSWER\n",
    "![](task2e_train_accuracy_shuffle_difference.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b)\n",
    "![](task3b_softmax_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "![](task3b_softmax_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3d)\n",
    "FILL IN ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "Fill in image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "FILL IN ANSWER\n",
    "\n",
    "![](task4b_softmax_weight.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "FILL IN ANSWER\n",
    "\n",
    "![](task4c_l2_reg_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "![](task4d_l2_reg_norms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "FILL IN ANSWER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python38164bitpy38condac1f68ca5407a4349b0d7e37676f2fbb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

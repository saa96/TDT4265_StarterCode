{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "Having that:\n",
    "$$ w_{j,i} =: w_{j,i} - \\alpha \\frac{\\partial C}{\\partial w_{j,i}}$$\n",
    "$$ \\frac{\\partial C}{\\partial w_{j,i}} = \\frac{\\partial C}{\\partial z_j}\\frac{\\partial z_j}{\\partial w_{j,i}} = \\delta_j \\frac{\\partial}{\\partial w_{j,i}} \\sum_{i=0}^I w_{j,i}x_i = \\delta_j x_i$$\n",
    "Which shows that:\n",
    "$$ w_{j,i} =: w_{j,i} - \\alpha \\delta_j x_i$$\n",
    "\n",
    "Next we want to show that:\n",
    "$$\\delta_j = f'(z_j)\\sum_k w_{k,j}\\delta_k$$\n",
    "Starting from that $ \\delta_j = \\frac{\\partial C}{\\partial z_j}$. This is the effect on the cross-entropy loss from รก spesific node in the hidden layer. This effekt is propagated through the output layer, meaning each output node will contain some of this effect, thus:\n",
    "$$\\delta_j = \\frac{\\partial C}{\\partial z_j} = \\sum_k \\frac{\\partial C}{\\partial z_k} \\frac{\\partial z_k}{\\partial z_j} = \\sum_k \\delta_k \\frac{\\partial z_k}{\\partial z_j}$$\n",
    "$$z_k = \\sum_j w_{k,j} a_j + b_k$$\n",
    "The above formula says that the output of a node is the weighted sum of effects from the previous layer.\n",
    "Moving on from the result of the expanded equation for $\\delta_j$ we have:\n",
    "\n",
    "$$\\frac{\\partial z_k}{\\partial z_j} = \\frac{\\partial z_k}{\\partial a_j} \\frac{\\partial a_j}{\\partial z_j} = w_{k,j} f'(z_j)$$\n",
    "\n",
    "Combining the \"components\" that was found above we get that:\n",
    "$$\\delta_j = f'(z_j) \\sum_k w_{k,j} \\delta_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "From the hidden layer (j) to the output layer (k), we have:\n",
    "$$ \\bold{W}^{l+1} := \\bold{W}^{l+1} - \\alpha (\\delta^{l+1})^T \\cdot \\bold{a}^l$$\n",
    "Where $l=$ first layer, and $l+1=$ next layer.\n",
    "\n",
    "For input layer (i) to the hidden layer (j) we have:\n",
    "$$ \\bold{W}^{l} := \\bold{W}^{l} - \\alpha (\\delta^{l})^T \\cdot \\bold{x}$$\n",
    "\n",
    "where:\n",
    "$$ \\delta^l = f'(\\bold{z}^l) (\\bold{W}^{l+1})^T \\cdot \\delta^{l+1}$$\n",
    "\n",
    "The dimentions of the matrixes and vectors are as follows:\n",
    "$$ \\bold{x} \\text{ } \\epsilon \\text{ } \\R^I$$\n",
    "$$ \\bold{W}^{l} \\text{ } \\epsilon \\text{ } \\R^{JxI}$$\n",
    "$$ \\bold{\\delta}^l \\text{ } \\epsilon \\text{ } \\R^J$$\n",
    "$$ \\bold{a}^l \\text{ } \\epsilon \\text{ } \\R^J$$\n",
    "$$ \\bold{W}^{l+1} \\text{ } \\epsilon \\text{ } \\R^{KxJ}$$\n",
    "$$ \\bold{\\delta}^{l+1} \\text{ } \\epsilon \\text{ } \\R^K$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2a)\n",
    "\n",
    "Mean = 33.55274553571429\n",
    "Standard deviation = 78.87550070784701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](task2c_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "The total number of parameters is the sum of the total number of weights and the total number of biases. This is given by:\n",
    "$784\\cdot64 + 64\\cdot10 + 784 + 64 = 50816$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs:\n",
    "\n",
    "Without improvements: 49 epochs \\\n",
    "With improved weight init: 49 epochs \\\n",
    "With improved weight and sigmoid: 39 epochs \\\n",
    "With improved weight and sigmoid, and momentum: 39 epochs \\\n",
    "\n",
    "As seen from the plot, there is no signs of overfitting of the training data. When implementing the sigmoid function, early stopping kicked in at epoch 39, ti epochs earlier than without it. Improved weights initialization and sigmoid function improved convergence properties, but by included the momentum function, convergence was sped up considerably.\n",
    "\n",
    "![](task3_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "As seen from the plot, cross-entropy loss and validation accuracy were somewhat worse when using 32 neurons in the hidden layer. In addition, early stopping kicked in at epoch 44 instead of 39.\n",
    "\n",
    "![](task4a_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "Using 128 neurons in the hidden layer, the final cross-entropy loss and validation accuracy actually improved. Also, although early stopping kicked in at 39 epochs, the increased complexity increased calculation time.\n",
    "\n",
    "![](task4b_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "FILL IN ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "FILL IN ANSWER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
